\section{Learning Environments}
\label{sec:environments}
In previous chapters, we have discussed the intersection between our \gls{rl} framework and both multi-objective decomposition-based learning and traditional single-objective \gls{rl}. 
Although all environments used in this work can be formulated as multi-objective, their experimental purposes differ. 
Some environments are designed to emphasize the construction and analysis of the Pareto front, focusing on the agentâ€™s ability to discover a diverse set of trade-off solutions. 
Others are employed to evaluate the learning dynamics and sample efficiency of the proposed algorithm when facing multiple objectives under data constraints or limited interaction budgets. 
This distinction enables a comprehensive assessment of DyLam across complementary perspectives: one highlighting its capacity to approximate optimal Pareto sets, and another emphasizing its learning efficiency in practical, data-driven scenarios.

\subsection{Pareto-Oriented Setups}
\label{sec:pareto_oriented_setups}

